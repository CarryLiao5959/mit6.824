# 1 引言

在过去的五年中，我们和谷歌的许多其他人一起实现了数百种专用计算，这些计算处理大量原始数据（如抓取的文档、网络请求日志等）以计算各种类型的派生数据，如倒排索引、网页文档的图形结构的各种表示、每个主机抓取的页面数的摘要、给定日期内最频繁查询的集合等。大多数此类计算在概念上都很简单。然而，输入数据通常很大，计算必须在数百或数千台机器上分布进行，以便在合理的时间内完成。如何并行化计算、分布数据以及处理故障等问题使得原本简单的计算被大量复杂的代码所掩盖。

为了应对这种复杂性，我们设计了一种新的抽象，它让我们能够表达我们试图进行的简单计算，但却隐藏了并行化、容错、数据分布和负载平衡等混乱细节。我们的抽象启发于Lisp和许多其他函数语言中存在的map和reduce原语。我们意识到，我们的大多数计算涉及将map操作应用于我们输入中的每个逻辑"记录"，以计算一组中间键/值对，然后将reduce操作应用于所有具有相同键的值，以适当地组合派生数据。我们对带有用户指定map和reduce操作的功能模型的使用，使我们能够轻松地并行化大型计算，并使用重新执行作为容错的主要机制。

这项工作的主要贡献是一个简单而强大的接口，它能够自动并行化和分布大规模计算，并且与此接口的实现在大型集群的商业PC上实现了高性能。第2节描述了基本编程模型并给出了几个示例。第3节描述了针对我们基于集群的计算环境定制的MapReduce接口的实现。第4节描述了我们发现的编程模型的几种改进。第5节对各种任务的实现进行了性能测量。第6节探讨了在谷歌内部使用MapReduce的情况，包括我们在使用它作为我们生产索引系统重写基础的经验。第7节讨论了相关和未来的工作。