# 5 性能

在这一部分，我们将测量在大规模机器集群上运行两种计算的MapReduce性能。一种计算在大约一太字节的数据中搜索特定模式。另一种计算对大约一太字节的数据进行排序。

这两个程序代表了使用MapReduce的用户写的真实程序的大部分子集——一类程序将数据从一种表示形式转换为另一种表示形式，另一类程序从大数据集中提取少量有趣的数据。

## 5.1 集群配置

所有程序都在一个包含大约1800台机器的集群上执行。每台机器有两个2GHz的Intel Xeon处理器，启用了HyperThreading，4GB的内存，两个160GB的IDE硬盘，和一个千兆以太网链路。机器以两级树状交换网络布局，根部的总带宽约100-200Gbps。所有的机器都在同一个托管设施中，因此任意一对机器之间的往返时间少于一毫秒。

在4GB的内存中，大约1-1.5GB被集群上运行的其他任务占用。这些程序是在周末下午执行的，当时CPU，硬盘，和网络主要处于空闲状态。

## 5.2 Grep

grep程序扫描1010个100字节的记录，搜索一个相对稀少的三个字符的模式（模式在92,337个记录中出现）。输入分成大约64MB的片段（M=15000），并将全部输出放在一个文件中（R=1）。

图2显示了计算随时间的进度。Y轴显示扫描输入数据的速率。随着更多的机器被分配给这个MapReduce计算，速率逐渐提高，当分配了1764个工人时，速率达到最高，超过30GB/s。随着map任务的完成，速率开始下降，大约在计算开始80秒后达到零。整个计算从开始到结束大约需要150秒。这包括大约一分钟的启动开销。这个开销是由于将程序传播到所有的工作机器，以及与GFS交互以打开1000个输入文件集并获取进行局部优化所需的信息所导致的。

## 5.3 Sort
sort程序对1010个100字节的记录（大约1TB的数据）进行排序。这个程序是模仿TeraSort基准测试[10]。

排序程序的用户代码少于50行。一个三行的Map函数从文本行中提取一个10字节的排序键，然后发出键和原始文本行作为中间键/值对。我们使用了一个内置的Identity函数作为Reduce操作符。这个函数将中间键/值对不变地传递为输出键/值对。最终排序的输出被写入一组2路复制的GFS文件（也就是说，作为程序的输出写入了2TB的数据）。

像以前一样，输入数据被分成64MB的片段（M = 15000）。我们将排序的输出分成4000个文件（R = 4000）。分区函数使用键的初始字节将其分隔成R部分。

对于这个基准测试，我们的分区函数内置了对键的分布的知识。在一般的排序程序中，我们会添加一个预处理的MapReduce操作，收集键的样本，并使用样本键的分布来计算最终排序阶段的分隔点。

图3（a）显示了排序程序正常执行的进度。左上图显示了读取输入的速率。该速率在约13 GB/s时达到峰值，并在200秒后的所有映射任务完成后相当快地消失。请注意，输入速率小于grep。这是因为排序的映射任务花费了大约一半的时间和I/O带宽将中间输出写入它们的本地磁盘。相应的grep的中间输出大小可以忽略不计。

左中图显示了从映射任务到减少任务的数据通过网络发送的速率。这种混洗开始于第一个映射任务完成后的那一刻。图中的第一个隆起是针对大约1700个减少任务的第一批（整个MapReduce被分配了大约1700台机器，每台机器一次最多执行一个减少任务）。大约在计算300秒后，这些第一批减少任务中的一些完成，我们开始混洗剩余的减少任务的数据。所有的混洗在计算600秒后完成。

左下图显示了减少任务将排序数据写入最终输出文件的速率。第一次混洗结束和开始写入之间有一段延迟，因为机器忙于对中间数据进行排序。写入以大约2-4 GB/s的速率进行一段时间。所有的写入在计算850秒后完成。包括启动开销，整个计算需要891秒。这与TeraSort基准测试的当前最佳报告结果1057秒类似[18]。

需要注意的几点：由于我们的局部性优化，输入速率高于混洗速率和输出速率——大部分数据是从本地磁盘读取的，绕过了我们相对带宽受限的网络。混洗速率高于输出速率，因为输出阶段写入了两份排序数据（我们出于可靠性和可用性的原因复制了输出）。我们写两份副本，因为这是我们的底层文件系统提供的可靠性和可用性的机制。如果底层文件系统使用纠错编码[14]而不是复制，那么写入数据的网络带宽需求会减少。

这种测试结果表明，即使在处理大数据集时，MapReduce也能保持良好的性能，甚至在机器数量多、数据量大的情况下也是如此。通过对大规模集群的有效使用，MapReduce能够在可接受的时间内完成对大规模数据的复杂计算，如搜索和排序。

然而，这并不意味着在所有情况下MapReduce都能保持高效的性能。例如，如果Map或Reduce函数执行的计算非常复杂，那么处理时间可能会增加，影响整体性能。此外，如果对MapReduce进行了不合适的配置（例如，选择了不恰当的Map或Reduce任务数量），那么性能也可能会受到影响。因此，对MapReduce程序的性能进行优化是一项重要的工作。

总的来说，上述测试结果表明，MapReduce是一种有效的大规模数据处理工具，能够在处理大数据集时保持良好的性能。

## 5.4 备份任务的影响

在图3（b）中，我们展示了一个禁用了备份任务的排序程序执行过程。该执行流程与图3（a）中显示的类似，只是存在一个非常长的尾部，几乎没有写入活动发生。在960秒之后，除了5个Reduce任务之外的所有任务都已完成。然而，这最后几个滞后者直到300秒后才完成。整个计算耗时1283秒，总用时增加了44%。

## 5.5 机器故障

在图3（c）中，我们展示了一个故意在计算开始几分钟后杀掉1746个worker进程中的200个进程的排序程序执行过程。底层的集群调度器立即在这些机器上重新启动新的worker进程（因为只有进程被杀掉，机器仍然正常工作）。

worker的死亡表现为负输入率，因为一些之前完成的map工作消失了（因为相应的map worker被杀掉），需要重新做。这些map工作的重新执行相对较快。整个计算包括启动开销在内，完成时间为933秒（比正常执行时间只增加了5%）。