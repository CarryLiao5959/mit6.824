# 7 相关工作

许多系统提供了有限的编程模型，并利用这些限制自动并行化计算。例如，可以在 N 个处理器上使用并行前缀计算[6, 9, 13]在 log N 时间内计算 N 元素数组的所有前缀的关联函数。可以将 MapReduce 视为基于我们在大型现实世界计算中的经验，对这些模型的一种简化和精简。更重要的是，我们提供了一个容错的实现，可以扩展到数千个处理器。相比之下，大多数并行处理系统只在较小的规模上实现，并将处理机器故障的细节留给程序员。

批量同步编程[17]和一些 MPI 原语[11]提供了更高级别的抽象，使程序员更容易编写并行程序。这些系统和 MapReduce 的一个关键区别是，MapReduce 利用限制的编程模型来自动并行化用户程序，并提供透明的容错。

我们的局部性优化借鉴了如主动磁盘[12, 15]等技术的灵感，其中计算被推入接近本地磁盘的处理元素，以减少通过 I/O 子系统或网络发送的数据量。我们在直接连接了少量磁盘的商用处理器上运行，而不是直接在磁盘控制器处理器上运行，但总体方法是相似的。

我们的备份任务机制类似于 Charlotte System[3]中使用的急切调度机制。简单的急切调度的一个缺点是，如果一个给定的任务导致重复的失败，整个计算无法完成。我们通过我们跳过坏记录的机制来修复这个问题的一些实例。

MapReduce 的实现依赖于一个内部的集群管理系统，该系统负责在大量共享机器上分发和运行用户任务。虽然不是本文的重点，但集群管理系统在精神上与 Condor[16]等其他系统相似。

作为 MapReduce 库的一部分的排序设施的操作类似于 NOW-Sort[1]。源机器（map工作器）将要排序的数据划分并发送到 R 个 reduce 工作器之一。每个 reduce 工作器在本地（如果可能的话，在内存中）对其数据进行排序。当然，NOW-Sort 没有我们的库中广泛应用的用户可定义的 Map 和 Reduce 函数。

River[2] 提供了一个编程模型，其中进程通过在分布式队列上发送数据来相互通信。像 MapReduce 一样，River 系统试图在存在由异构硬件或系统扰动引入的非均匀性的情况下提供良好的平均性能。River通过仔细调度磁盘和网络传输以实现平衡的完成时间来实现这一点。MapReduce采用了不同的方法。通过限制编程模型，MapReduce框架能够将问题分割成大量的细粒度任务。这些任务在可用的工作人员上动态地进行调度，因此更快的工作人员会处理更多的任务。限制的编程模型还允许我们在作业结束时安排任务的冗余执行，这大大减少了在存在非均匀性（如慢速或卡住的工作人员）的情况下的完成时间。

BAD-FS [5] 的编程模型与 MapReduce 有很大的不同，并且与 MapReduce 不同，它针对的是在广域网上执行作业。然而，有两个基本的相似性。 （1）两个系统都使用冗余执行来恢复由故障引起的数据丢失。 （2）两者都使用基于位置的调度来减少通过拥塞的网络链接发送的数据量。

TACC [7] 是一个旨在简化构建高可用网络服务的系统。像 MapReduce 一样，它依赖于重新执行作为实现容错的机制。